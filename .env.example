# Environment Configuration

# LLM Provider Configuration
LLM_PROVIDER=ollama  # Options: "gemini", "openai", or "ollama" (local)

# API Keys (for cloud providers)
# GEMINI_API_KEY=your_gemini_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llava  # Options: llava, llama3.2-vision, bakllava, etc.

# Model Configuration
GEMINI_MODEL=gemini-1.5-flash  # Options: gemini-1.5-flash, gemini-1.5-pro
# OPENAI_MODEL=gpt-4o-mini  # Options: gpt-4o-mini, gpt-4o

# Processing Limits
MAX_PAGES_PER_INVOICE=50
MAX_FILE_SIZE_MB=10

# LLM Settings
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=60

# Logging
LOG_LEVEL=INFO
